---
title: ä½¿ç”¨hexoæ­å»ºåšå®¢
date: 2016-07-05 18:03:31
tags: hexo
categories: 
    - æ•™ç¨‹
---

# å‚è€ƒåšå®¢
    
æ„Ÿè°¢ [å²æœˆå¦‚æ­Œ](http://lovenight.github.io) çš„è¿™ä¸ª[ã€ŠHexo 3.1.1 é™æ€åšå®¢æ­å»ºæŒ‡å—ã€‹](http://lovenight.github.io/2015/11/10/Hexo-3-1-1-é™æ€åšå®¢æ­å»ºæŒ‡å—/)åŒæ—¶æ„Ÿè°¢è¿™ä¸ª[ã€Šå‘ç™¾åº¦æ¨é€hexoåšå®¢æ‰€æœ‰é“¾æ¥çš„Pythonè„šæœ¬ã€‹](http://lovenight.github.io/2015/11/18/å‘ç™¾åº¦æ¨é€hexoåšå®¢æ‰€æœ‰é“¾æ¥çš„Pythonè„šæœ¬/)(åˆ«é—®æˆ‘ä¸ºå•¥ç‚¹ä¸å¼€ï¼Œè¿™ä¸ªè¦é—®åšä¸»ï¼Œä¸è¿‡è¦çœ‹è¿™ä¸ªæ–‡ç« ä¹Ÿä¸æ˜¯æ²¡åŠæ³•çš„ğŸ˜‚ï¼Œå› ä¸ºè¿™ä¸ªåšå®¢ä¹Ÿç”¨gitç®¡ç†çš„ã€‚ã€‚ã€‚ä½ æ‡‚)


# è„šæœ¬ä¿®æ”¹

ä¸Šé¢è¯´çš„åšä¸»å¤§çº¦ç”¨çš„æ˜¯windowsï¼Œæ‰€ä»¥è„šæœ¬å¹¶ä¸èƒ½ç«‹é©¬çš„è¿è¡Œåœ¨Macä¸Šï¼Œéœ€è¦åšäº›ä¿®æ”¹ï¼šæ•…ä¿®æ”¹ä¸ºï¼š

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Author: LoveNight
# @Date:   2015-11-16 20:45:59
# @Last Modified by:   LoveNight
# @Last Modified time: 2015-11-18 18:07:19

# @Last Modified by:   Keith
# @Last Modified time: 2016-07-06 16:22:45
import os
import sys
import json
from bs4 import BeautifulSoup as BS
import requests
#import msvcrt

"""
hexo åšå®¢ä¸“ç”¨ï¼Œå‘ç™¾åº¦ç«™é•¿å¹³å°æäº¤æ‰€æœ‰ç½‘å€

æœ¬è„šæœ¬å¿…é¡»æ”¾åœ¨hexoåšå®¢çš„æ ¹ç›®å½•ä¸‹æ‰§è¡Œï¼éœ€è¦å·²å®‰è£…ç”Ÿæˆç™¾åº¦ç«™ç‚¹åœ°å›¾çš„æ’ä»¶ã€‚
ç™¾åº¦ç«™é•¿å¹³å°æäº¤é“¾æ¥ï¼šhttp://zhanzhang.baidu.com/linksubmit/index
ä¸»åŠ¨æ¨é€ï¼šæœ€ä¸ºå¿«é€Ÿçš„æäº¤æ–¹å¼ï¼Œæ¨èæ‚¨å°†ç«™ç‚¹å½“å¤©æ–°äº§å‡ºé“¾æ¥ç«‹å³é€šè¿‡æ­¤æ–¹å¼æ¨é€ç»™ç™¾åº¦ï¼Œä»¥ä¿è¯æ–°é“¾æ¥å¯ä»¥åŠæ—¶è¢«ç™¾åº¦æ”¶å½•ã€‚
ä»ä¸­æ‰¾åˆ°è‡ªå·±çš„æ¥å£è°ƒç”¨åœ°å€

pythonç¯å¢ƒï¼š
pip install beautifulsoup4
pip install requests
xcode-select --install	
pip install lxml 

"""

# âŒâŒâŒ æŠ„çš„éœ€è¦æ›´æ”¹è¿™ä¸ªURLï¼ï¼è¿™æ˜¯æˆ‘çš„ï¼ï¼âŒâŒâŒ
url = 'http://data.zz.baidu.com/urls?site=https://madordie.github.io&token=j33t0VEPFl24tJ8N'
baidu_sitemap = os.path.join(sys.path[0], 'public', 'baidusitemap.xml')
google_sitemap = os.path.join(sys.path[0], 'public', 'sitemap.xml')
sitemap = [baidu_sitemap, google_sitemap]

assert (os.path.exists(baidu_sitemap) or os.path.exists(
    google_sitemap)), "æ²¡æ‰¾åˆ°ä»»ä½•ç½‘ç«™åœ°å›¾ï¼Œè¯·æ£€æŸ¥ï¼"


# ä»ç«™ç‚¹åœ°å›¾ä¸­è¯»å–ç½‘å€åˆ—è¡¨
def getUrls():
    urls = []
    for _ in sitemap:
        if os.path.exists(_):
            with open(_, "r") as f:
                xml = f.read()
        soup = BS(xml, "xml")
        tags = soup.find_all("loc")
        urls += [x.string for x in tags]
        if _ == baidu_sitemap:
            tags = soup.find_all("breadCrumb", url=True)
            urls += [x["url"] for x in tags]
    return urls


# POSTæäº¤ç½‘å€åˆ—è¡¨
def postUrls(urls):
    urls = set(urls)  # å…ˆå»é‡
    print("ä¸€å…±æå–å‡º %s ä¸ªç½‘å€" % len(urls))
    print(urls)
    data = "\n".join(urls)
    return requests.post(url, data=data).text


if __name__ == '__main__':

    urls = getUrls()
    result = postUrls(urls)
    print("æäº¤ç»“æœï¼š")
    print(result)
#    msvcrt.getch()
```